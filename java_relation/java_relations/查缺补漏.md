# 查缺补漏

## 两种 HTTP 请求方法：GET 和 POST

在客户机和服务器之间进行请求-响应时，两种最常被用到的方法是：GET 和 POST。

- *GET* - 从指定的资源请求数据。
- *POST* - 向指定的资源提交要被处理的数据

![image-20200811204948165](C:\Users\xwj\AppData\Roaming\Typora\typora-user-images\image-20200811204948165.png)

## 间隙锁

间隙锁就是锁住索引记录之间的间隙的锁。多亏有这个间隙锁，当你2次运行相同的查询时，你可以得到相同的结果集，而不用管是否有其他的连接修改了表数据。(主要为了解决幻读)

例如：

如果你执行`SELECT * FROM id > 1000 FOR UPDATE` 2次，你期望得到相同的结果集。为了实现这个目的，`INNODB`以独占锁锁定全部通过WHERE条件找到的索引项，并用共享锁锁定他们之间的间隙。

`MYSQL`用`REPEATABLE READ`作为默认的事务隔离级别，所以它需要锁定索引记录和间隙记录，去解决幻读和基于语句的复制的一致性。如果你的应用能够处理幻读并且二进制登记为行格式，把隔离级别改成`READ COMMITTED`将帮助你避免所有的这些额外锁。最后一个建议，坚持使用短事务。

## 行锁

`InnoDB`行锁是通过给索引上的索引项加锁来实现的。

行锁的实现

注意：1.行锁必须要有索引才能实现，否则会自动锁全表

​			2.两个事务不能锁定同一个索引

## 假如一张表有一亿条数据，需要查找其中某一条数据。

如果把这张表转换成平衡树结构（一棵非常茂盛和节点非常多的树）

**note**:

1.索引就是对一个表的某个字段，或者多个字段（联合索引）建立一种特殊的存储结构（b tree）。

  主键是索引的一种，是唯一索引的特殊类型。创建主键的时候，数据库默认会为主键创建一个唯一索引。

## 聚集索引和辅助索引

### 聚集索引

按照每张表的主键构成一棵B+树，叶子节点中存放整张表的行记录数据，也将聚集索引的叶子节点成为数据页，每个数据页之间通过一个双向链表来进行链接。数据页存放的是每行的所有记录，非数据页存放的是键值和指向数据页的偏移量。一张表只能有一个聚集索引。

- 可以在叶子节点直接找到数据
- 对于主键的排序查找和范围查找速度非常快，因为聚集索引是逻辑上连续的。比如查询后10条数据，由于B+树索引是双向链表，可以很快找到随后一个数据页，然后取出最后的10条数据。

### 辅助索引

也称非聚集索引，按照每张表创建的索引列创建一棵B+树，叶子节点并不包含行记录的全部数据。叶子节点包含键值和书签，书签用来告诉`InnoDB`存储引擎在哪可以找到与索引对应的行数据，通常是襄阳行数据的聚集索引键。每张表可以有多个辅助索引

  如果某个查询是通过辅助索引查找数据的，则查找过程为：先遍历辅助索引并找到叶节点找到指针获取主键索引的主键，然后通过主键索引找到对应的页从而找到一个完整的行记录。注：每执行一次查询就是一次IO，比如 辅助索引树高度为3，聚集索引树高度为2，则通过辅助索引查询数据时就要进行3+2次逻辑IO最终得到一个数据页。

### 联合索引

联合索引也是一个B+树，只不过键值的数量为多个，比如联合索引为（a,b）,b相对于a才是有序的,可以用二维数据理解一下，比如A(3,5),在键A做的的都是小于（3,5）的，右边的都是大于等于（3,5）,用如下语句创建了一张表

### 覆盖索引

也称索引覆盖，即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。

1. 辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以较少大量的IO操作
2. 做统计时，不会通过聚集索引来统计，通过辅助索引就可以实现统计，也减少了IO

## 遇到的内存泄漏,怎么解决

### 内存泄漏

先前申请了内存空间而忘记了释放。如果程序中存在对无用对象的引用，那么这些对象就会驻留内存，消耗内存，因为无法让垃圾回收器`GC`验证这些对象是否不再需要。

`Java`内存泄漏的根本原因是什么呢？长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄漏，尽管短生命周期对象已经不再需要，但是因为长生命周期持有它的引用而导致不能被回收，这就是`Java`中内存泄漏的发生场景。                

### 详细Java中的内存泄漏

**1.Java内存回收机制**

不论哪种语言的内存分配方式，都需要返回所分配内存的真实地址，也就是返回一个指针到内存块的首地址。Java中对象是采用new或者反射的方法创建的，这些对象的创建都是在堆（Heap）中分配的，所有对象的回收都是由Java虚拟机通过垃圾回收机制完成的。GC为了能够正确释放对象，会监控每个对象的运行状况，对他们的申请、引用、被引用、赋值等状况进行监控，Java会使用有向图的方法进行管理内存，实时监控对象是否可以达到，如果不可到达，则就将其回收，这样也可以消除引用循环的问题。在Java语言中，判断一个内存空间是否符合垃圾收集标准有两个：一个是给对象赋予了空值null，以下再没有调用过，另一个是给对象赋予了新值，这样重新分配了内存空间。

**2.Java内存泄漏引起的原因**

内存泄漏是指无用对象（不再使用的对象）持续占有内存或无用对象的内存得不到及时释放，从而造成内存空间的浪费称为内存泄漏。内存泄露有时不严重且不易察觉，这样开发者就不知道存在内存泄露，但有时也会很严重，会提示你Out of memory。

Java内存泄漏的根本原因是什么呢？长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄漏，尽管短生命周期对象已经不再需要，但是因为长生命周期持有它的引用而导致不能被回收，这就是Java中内存泄漏的发生场景。具体主要有如下几大类：

**1、静态集合类引起内存泄漏：**

像HashMap、Vector等的使用最容易出现内存泄露，这些静态变量的生命周期和应用程序一致，他们所引用的所有的对象Object也不能被释放，因为他们也将一直被Vector等引用着。

**2、当集合里面的对象属性被修改后，再调用remove()方法时不起作用。**

**5、内部类和外部模块的引用**

内部类的引用是比较容易遗忘的一种，而且一旦没释放可能导致一系列的后继类对象没有释放。此外程序员还要小心外部模块不经意的引用，例如程序员A 负责A 模块，调用了B 模块的一个方法如：

public void registerMsg(Object b);

这种调用就要非常小心了，传入了一个对象，很可能模块B就保持了对该对象的引用，这时候就需要注意模块B 是否提供相应的操作去除引用。

**6、单例模式**

不正确使用单例模式是引起内存泄漏的一个常见问题，单例对象在初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部的引用，那么这个对象将不能被JVM正常回收，导致内存泄漏。

### 如何解决内存泄漏

如何查找引起内存泄漏的原因一般有两个步骤:第一是安排有经验的编程人员对代码进行走查和分析，找出内存泄漏发生的位置;第二是使用专门的内存泄漏测试工具进行测试。

## Java对HashMap中的key或者value值进行排序

```java
import java.util.*;

public class Main {
    public static void main(String[] args) {
        Map<String, Integer> map = new HashMap<>();
        map.put("d",2);
        map.put("c",1);
        map.put("b",4);
        map.put("a",3);

        List<Map.Entry<String,Integer>> infoIds = new ArrayList<Map.Entry<String, Integer>>(map.entrySet());

        Collections.sort(infoIds, new Comparator<Map.Entry<String, Integer>>() {
            @Override
            public int compare(Map.Entry<String, Integer> o1, Map.Entry<String, Integer> o2) {
                return (o1.getKey()).toString().compareTo(o2.getKey().toString());
            }
        });

        for (int i=0;i<infoIds.size();i++){
            String id = infoIds.get(i).toString();
            System.out.println(id + "");
        }
        System.out.println();

        Collections.sort(infoIds, new Comparator<Map.Entry<String, Integer>>() {
            @Override
            public int compare(Map.Entry<String, Integer> o1, Map.Entry<String, Integer> o2) {
                return (o1.getValue().toString()).compareTo(o2.getValue().toString());
            }
        });

        for (int i=0;i<infoIds.size();i++){
            String id = infoIds.get(i).toString();
            System.out.println(id + " ");
        }
    }
}
```

## SpringBootHttp接口请求

1、@RestController和@RequestMapping是springMVC的注解，不是springboot特有的
2、@RestController=@Controller+@ResponseBody
3、@SpringBootApplication=@Configuration+@EnableAutoConfiguration+@ComponentScan

- 首先利用@RestController注解类，在方法上可以用GetMapping()

- 分页参数利用`@RequestParam(defaultValue = "1) Integer page`从`controller`层传入.

- 如果是一个员工信息则是利用`@RequestBody Employee employee`。

![image-20200814202220213](C:\Users\xwj\AppData\Roaming\Typora\typora-user-images\image-20200814202220213.png)

- 路径中的参数传递利用`@PathVariable`。

# SpringBoot内置web容器及配置

我们知道的web项目都是需要部署到服务容器上，例如tomcat。

- SpringBoot支持封装Tomcat、Jetty和Undertow三种web容器。

## Spring为什么默认bean是单例的

- **减少了新生成实例的消耗**
  新生成实例消耗包括两方面，第一，spring会通过反射或者cglib来生成bean实例这都是耗性能的操作，其次给对象分配内存也会涉及复杂算法。
- **减少jvm垃圾回收**
  由于不会给每个请求都新生成bean实例，所以自然回收的对象少了。
- **可以快速获取到bean**
  因为单例的获取bean操作除了第一次生成之外其余的都是从缓存里获取的所以很快。

#### 单例bean的劣势

- 单例的bean一个很大的劣势就是他不能做到`线程安全`，由于所有请求都共享一个bean实例，所以这个bean要是有状态的一个bean的话可能在并发场景下出现问题，而原型的bean则不会有这样问题（但也有例外，比如他被单例bean依赖），因为给每个请求都新创建实例。

## GC日志有哪些？

```java
2014-07-18T16:02:17.606+0800（当前时间戳）: 611.633（时间戳）: [GC（表示Young GC） 611.633: [DefNew（单线程Serial年轻代GC）: 843458K（年轻代垃圾回收前的大小）->2K（年轻代回收后的大小）(948864K（年轻代总大小）), 0.0059180 secs（本次回收的时间）] 2186589K（整个堆回收前的大小）->1343132K（整个堆回收后的大小）(3057292K（堆总大小）), 0.0059490 secs（回收时间）] [Times: user=0.00（用户耗时） sys=0.00（系统耗时）, real=0.00 secs（实际耗时）]
```

如果对年轻代回收的日志，包含：当前的时间戳，年轻代垃圾回收前的大小，年轻代回收后的大小，本次回收的时间。整个堆回收前的大小，整个堆回收后的大小（堆总大小），回收时间，用户耗时，系统耗时，实际耗时。

## 如何在多态web服务器上共享session

比如：现在有三台php服务器，且实现了负载均衡，如何让这三台web服务器共享session数据？

session数据默认是以文件的形式保存在web服务器的磁盘上，一般都是用户登录成功的时候，保存session数据。

同一个用户登录后，就会将session保存在某个web服务器上，假设是保存在服务器A上，该用户访问网站的其他页面时，可能请求的就是服务器B或服务器C，但服务器B或服务器C上并没有该用户的session文件，这样，就会导致网站误认为该用户未登录，用户的登录状态丢失的问题。

归根结底，就是要解决多台web服务器共享session的问题，至少有以下三种方法：

### 1.**将本该保存在web服务器磁盘上的session数据保存到cookie中**

即用cookie会话机制替代session会话机制，将session数据保存到客户端浏览器的cookie中，这样同一个用户访问同一网站时，无论负载均衡到哪台web服务器，都不用再去服务器请求session数据，而直接获取客户端cookie中的session数据。如此，同一个用户的登录状态就不会丢失了。

但这样做，有三大弊端：

### 2.将本该保存在web服务器磁盘上的session数据保存到MySQL数据库中

`sessionid`还是利用cookie机制存储到客户端，但`session`数据却存放在`MySQL`服务器上。（需要建立`sessionid`和`session`数据行的对应关系）但这样做，只适合访问量比较小的网站。如果网站的访问量比较大，对`MySQL`服务器会造成很大压力。

### 3.将本该保存在web服务器磁盘上的session数据保存到内存数据库（memcache或redis）中。

memcache或redis是基于内存存储数据的，性能很高，尤其是高并发的情况下尤为合适。主要是因为从内存中读取数据要比从磁盘读取数据快很多。内存数据库还支持数据过期失效的机制，正好与session的过期机制对应，推荐使用redis内存数据库，因为它比memcache支持更多的数据类型，且支持内存数据备份到磁盘。

## HTTPS讲解

### 对称加密和非对称加密

对称加密比较简单，就是客户端和服务器共用同一个密钥，该密钥可以用于加密一段内容，同时也可以用于解密这段内容。对称加密的优点是加解密效率高，但是在安全性方面可能存在一些问题，因为密钥存放在客户端有被窃取的风险。对称加密的代表算法有：`AES`、DES等。

而非对称加密则要复杂一点，它将密钥分成了两种：公钥和私钥。公钥通常存放在客户端，私钥通常存放在服务器。使用公钥加密的数据只有用私钥才能解密，反过来使用私钥加密的数据也只有用公钥才能解密。非对称加密的优点是安全性更高，因为客户端发送给服务器的加密信息只有用服务器的私钥才能解密，因此不用担心被别人破解，但缺点是加解密的效率相比于对称加密要差很多。非对称加密的代表算法有：`RSA`、ElGamal等。

由于我们在传输数据时信息都是明文的，因此很容易出现数据被监听和窃取的情况。

![img](https://img-blog.csdnimg.cn/20200227221956996.png)

![img](https://img-blog.csdnimg.cn/20200227222025377.png)

非常关键的一步，浏览器该怎样才能获取到网站的公钥呢？虽然公钥是属于公开的数据，在网络上传输不怕被别人监听，但是如果公钥被别人篡改了怎么办？

![img](https://img-blog.csdnimg.cn/2020022722213554.png)

这个时候，就必须引入一个新的概念来打破僵局了：CA机构。

CA机构专门用于给各个网站签发数字证书，从而保证浏览器可以安全地获得各个网站的公钥。

证书制作完成后，CA机构会使用自己的私钥对其加密，并将加密后的数据返回给我们，我们只需要将获得的加密数据配置到网站服务器上即可。

然后，每当有浏览器请求我们的网站时，首先会将这段加密数据返回给浏览器，此时浏览器会用CA机构的公钥来对这段数据解密。

那么你可能会问了，有了CA机构之后就真的安全了吗？我们在浏览器端要使用CA机构的公钥来解密数据，那么又该如何安全地获取到CA机构的公钥呢？

这个问题就很好解决了，因为世界上的网站是无限多的，而CA机构总共就那么几家。任何正版操作系统都会将所有主流CA机构的公钥内置到操作系统当中，所以我们不用额外获取，解密时只需遍历系统中所有内置的CA机构的公钥，只要有任何一个公钥能够正常解密出数据，就说明它是合法的。

## 生产者和消费者-synchronized实现

```java
class Concurrentcomm{
    private static int Max = 10;
    LinkedList<String> linkedList = new LinkedList<>();
    
    //实现生产者方法
    public void product() throws Exception{
        synchronized(linkedList){
            while(Max == linkedList.size()){
                System.out.println("仓库已满，【生产者】：暂时不能执行生成任务");
                linkedList.wait();
            }
            linkedList.push("李四");
            System.out.println("【生产者】：生产了一个产品\t【现仓储量为】：" + linkedList.size());
            linkedList.notify();
        }
    }
    
    //实现消费者方法
    public void consumer() throws Exception{
        synchronized(linkedList){
            while(linkedList.size() == 0){
                System.out.println("仓库无货，【消费者】：暂时不能执行消费任务！");
                linkedList.wait();
            }
            linkedList.poll();
            System.out.println("【消费者】：消费了一个产品\t【仓储量为】："+ linkedList.size());
            likedList.notify();
        }
    }
}

public class Main(){
    private static int Max = 10;
    public static void main(String[] args){
        Concurrentcomm con = new Concurrentcomm();
        new Thread(new Runnable(){
            public void run(){
                try{
                    for(int i = 0;i<Max;i++){
                        Thread.sleep(0);
                        con.product();
                    }
                }catch(Exception e){
                    e.printStackTrace();
                }
            }
        }).start();
        
        new Thread(new Runnable(){
            public void run(){
                try{
                    Thread.sleep(10);
                    for(int i=0;i<Max;i++){
                        con.customer();
                    }
                }catch(Exception e){
                    e.printTrace();
                }
            }
        }).start();
    }
}
```

## Redis是单线程的，性能为什么这么快？

- 数据存储在内存
- 利用了一个IO多路复用
- 单线程，避免了不必要的上下文切换和竞争条件

## redis能否将数据持久化，如何实现？

- 能，将内存中的数据异步写入硬盘中，两种方式：`RDB`（默认）和`AOF`

- `RDB`持久化原理：通过`bgsave`命令触发，然后父进程执行fork操作创建子进程，子进程创建`RDB`文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换（定时一次性将所有数据进行快照生成一份副本存储在硬盘中）
  - 优点：是一个紧凑压缩的二进制文件，`Redis`加载`RDB`恢复数据远远快于`AOF`的方式。
  - 缺点：由于每次生成`RDB`开销较大，非实时持久化，

- `AOF`持久化原理：开启后，`Redis`每执行一个修改数据的命令，都会把这个命令添加到`AOF`文件中。
  - 优点：实时持久化。
  - 缺点：所以`AOF`文件体积逐渐变大，需要定期执行重写操作来降低文件体积，加载慢。

## 主从复制模式下，主挂了怎么办？redis提供了哨兵模式（高可用）

何谓哨兵模式？就是通过哨兵节点进行自主监控主从节点以及其他哨兵节点，发现主节点故障时自主进行故障转移。

哨兵的作用就是监控和选举，监控master 和 slave 是否正常，master宕机之后，重新选举。

**总而言之**：`redis`的主从复制和哨兵模式服务可以保证`redis`服务的高可用。

## Redis的内存回收策略

![image-20200817105406092](C:\Users\xwj\OneDrive\java_relations\查缺补漏\image-20200817105406092.png)

## 怎样看待redis使用单线程的，什么时候使用多线程比较好？

### 怎样看待redis使用单线程的？

1.`CPU`不是`redis`的瓶颈
2.`redis`的瓶颈主要在内存大小和网络的快慢
3.`redis`的`tps`能达到百万级（这已经够快了）

所有单线程已经够快了，所有不用多线程了。

### 什么时候使用多线程比较好？

`redis`实际上是采用了线程封闭的观念，把任务封闭在一个线程，自然避免了线程安全问题，不过对于需要依赖**多个`redis`操作的复合操作**来说，依然需要锁，而且有可能是分布式锁。

## HashMap应不应该设置参数呢?对于参数设置要怎么注意呢?

为了减小扩容次数，需要设置初始容量；initialCapacity = (需要存储的元素个数 /负载因子) + 1；jdk会自动把设置的初始容量设置到最近的2的n次方。

## HashMap扩容的时间复杂度，如何提升扩容方面的效率

而在hashmap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。

需要遍历原来的数组或者链表o(n)。

扩容的成本并不低，因为需要遍历一个时间复杂度为O(n)的数组，并且为其中的每个enrty进行hash计算。加入到新数组中，所以最好的情况是能够合理的使用HashMap的构造方法创建合适大小的HashMap，使得在不浪费内存的情况下，尽量减少扩容。

## CAS是什么东西？

Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。

## 线程池中workQueue的三种类型的区别

### SynchronousQueue

SynchronousQueue没有容量，是无缓冲等待队列，是一个不存储元素的阻塞队列，会直接将任务交给消费者，必须等队列中的添加元素被消费后才能继续添加新的元素。使用SynchronousQueue阻塞队列一般要求maximumPoolSizes为无界，避免线程拒绝执行操作。

### LinkedBlockingQueue

LinkedBlockingQueue是一个无界（没有大小限制）缓存等待队列。当前执行的线程数量达到corePoolSize的数量时，剩余的元素会在阻塞队列里等待，在使用此阻塞队列时maximumPoolSizes就相当于无效了。

### ArrayBlockingQueue

ArrayBlockingQueue是一个有界缓存等待队列，可以指定缓存队列的大小，当线程数量大于corePoolSize时，多余的任务会缓存在ArrayBlockingQueue队列中等待有空闲的线程时继续执行；当ArrayBlockingQueue满时，则又会开启新的线程去执行，直到线程数量达到maximumPoolSize；当线程数已经达到最大的maximumPoolSize时，再有新的任务到达时会执行拒绝执行策略（RejectedExecutionException）。

## 产生CPU100%的原因

某一程序一直占用CPU是导致CPU100%的原因，大概有以下几种情况：

```
1、Java 内存不够或溢出导致GC overhead问题, GC overhead 导致的CPU 100%问题;

2、死循环问题. 如常见的HashMap被多个线程并发使用导致的死循环, 或者死循环;

3、某些操作一直占用CPU
```

## 如何分库分表？

分表和表分区的目的就是减少数据库的负担，提高数据库的效率，通常点来讲就是提高表的增删改查效率。

### 垂直（纵向）切分

垂直切分常见有垂直分库和垂直分表两种。

垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。例如：在银行系统中，将客户数据，存款数据，贷款等数据表分别存储于数据库。

![img](https://img-blog.csdnimg.cn/2018122823205817)

垂直分表是基于数据库中的"列"进行，某个**表字段较多**，可以新建一张扩展表，将**不经常用或字段长度较大的字段**拆分出去到扩展表中。

![img](https://img-blog.csdnimg.cn/2018122823205868)

缺点：

- 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度
- 分布式事务处理复杂
- 依然存在单表数据量过大的问题（需要水平切分）

## 水平（横向）切分

水平切分分为库内分表和分库分表，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。

![img](https://img-blog.csdnimg.cn/20181228232058107)

**分库分表**

分库分表则是将切分出来的子表，分散到不同的数据库中，从而使得单个表的数据量变小，达到分布式的效果。

## RabbitMQ

**1） 对于数据量大或者处理耗时长的操作，我们可以引入 MQ 实现异步通信，减少客户端的等待，提升响应速度。**

**2） 对于改动影响大的系统之间，可以引入 MQ 实现解耦，减少系统之间的直接依赖。**

**3） 对于会出现瞬间的流量峰值的系统，我们可以引入 MQ 实现流量削峰，达到保护应用和数据库的目的。**

### 工作模型

1.Broker

2.Connection

3.Channel

4.Queue

5.Exchange

6.Vhost

### 路由方式

**直连 Direct**

- 队列与直连类型的交换机绑定，需指定一个精确的绑定键。生产者发送消息时会携带一个路由键。只有当路由键与其中的某个绑定键完全匹配时，这条消息才会从交换机路由到满足路由关系的此队列上。

![img](https://img2018.cnblogs.com/blog/1725845/201909/1725845-20190919214237826-1819984778.png)

**主题 Topic**

队列与主题类型的交换机绑定时，可以在绑定键中使用通配符。两个通配符：#：0 个或者多个单词、*：不多不少一个单词

单词（word）指的是用英文的点“.”隔开的字符。例如 abc.def 是两个单词。

![img](https://img2018.cnblogs.com/blog/1725845/201909/1725845-20190919214617865-529581997.png)



**广播 Fanout**

主题类型的交换机与队列绑定时，不需要指定绑定键。因此生产者发送消息到广播类型的交换机上，也不需要携带路由键。消息达到交换机时，所有与之绑定了的队列，

都会收到相同的消息的副本。

ConfirmCallBack：确认，ReturnCallBack：回发。

## order by和group by的区别？

### order by:用来对数据库的一组数据进行排序

desc：降序

asc：升序

### group by：

“By”指定的规则对数据进行分组，所谓的分组就是将一个“数据集”划分成若干个“小区域”，然后针对若干个“小区域”进行数据处理。

## 认证和授权有什么区别

Authentication（认证）：你是谁？

Authorization（授权）：能干什么？



实现`FilterInvocationSecurityMetadataSource`这个接口，重写了里面的`getAttributes`方法，用于获取当前请求地址对应的角色信息。接着也配置了`AccessDecisionManager`接口，从`FilterInvocationSecurityMetadataSource`返回的集合会到达这里，重写了`decide()`方法，用于验证当前登录的角色能否和数据库查询的角色进行匹配。当匹配上的时候进行返回。

